{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R6_ExternalLab_AIML_(1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YYk8NG3yOIT9"
      },
      "source": [
        "### A MNIST-like fashion product database\n",
        "\n",
        "In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tFO6PuxzOIT_"
      },
      "source": [
        "### Load tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVav8BR9RkTv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9eb8fe10-e415-400e-a462-033d603264bc"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "efNjNImfOIUC",
        "outputId": "c5cfe363-b242-4e09-d031-7275e719dd57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l9C4aAIGOIUH",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HcoZBStrOIUQ"
      },
      "source": [
        "### Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XA1WsFSeOIUS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5be7f475-05c1-4958-96b4-5cc00f80a317"
      },
      "source": [
        "import keras"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qnbx7TyQOIUY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "d60dad3c-a8a8-4f5a-8768-7ca26f169eea"
      },
      "source": [
        "(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 4us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UbiHj5YPOIUc",
        "outputId": "9b816ddf-e639-4d9d-8f4c-5bf8a4f80052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(testY[0:5])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 2 1 1 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lDAYzkwyOIUj"
      },
      "source": [
        "### Convert both training and testing labels into one-hot vectors.\n",
        "\n",
        "**Hint:** check **tf.keras.utils.to_categorical()**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vBlfYlANOIUk",
        "colab": {}
      },
      "source": [
        "trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
        "testY = tf.keras.utils.to_categorical(testY, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RHV3b9mzOIUq",
        "outputId": "b6b42ee8-94b8-4816-d078-391bbb2bcd4c",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "print(trainY.shape)\n",
        "print('First 5 examples now are: ', trainY[0:5])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "First 5 examples now are:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FwhQ8e7VOIUw"
      },
      "source": [
        "### Visualize the data\n",
        "\n",
        "Plot first 10 images in the triaining set and their labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AvDML2OoOIUx",
        "outputId": "92f25914-a139-48d6-cdfd-6011735ff404",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# visualizing the first 10 images in the dataset and their labels\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 1))\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.imshow(trainX[i].reshape(28, 28), cmap=\"gray\")\n",
        "    plt.axis('off')\n",
        "    print('label for each of the below image: %s' % (np.argmax(trainY[0:10][i])))\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label for each of the below image: 9\n",
            "label for each of the below image: 0\n",
            "label for each of the below image: 0\n",
            "label for each of the below image: 3\n",
            "label for each of the below image: 0\n",
            "label for each of the below image: 2\n",
            "label for each of the below image: 7\n",
            "label for each of the below image: 2\n",
            "label for each of the below image: 5\n",
            "label for each of the below image: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAA9CAYAAACpzLMWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmG0FDwFsAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x72 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l4TbJGeSOIU4"
      },
      "source": [
        "### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ac06XZZTOIU6",
        "colab": {}
      },
      "source": [
        "# Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Reshape data from 2D to 1D -> 28x28 to 784\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "\n",
        "# Add Dense Layer which provides 10 Outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Comile the model\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3hQpLv3aOIU_"
      },
      "source": [
        "### Execute the model using model.fit()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O59C_-IgOIVB",
        "outputId": "b14ed7c2-d477-46a8-e872-7832c66ae5d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(trainX, trainY, validation_data=(testX, testY), epochs=50, batch_size = trainX.shape[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 233.7262 - accuracy: 0.1228 - val_loss: 7658.1616 - val_accuracy: 0.2841\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 1s 9us/sample - loss: 7577.1504 - accuracy: 0.2860 - val_loss: 13597.7988 - val_accuracy: 0.3289\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 13565.4033 - accuracy: 0.3320 - val_loss: 13604.6914 - val_accuracy: 0.2497\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 13559.5645 - accuracy: 0.2504 - val_loss: 13506.5244 - val_accuracy: 0.2584\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 0s 8us/sample - loss: 13477.7344 - accuracy: 0.2549 - val_loss: 12677.6514 - val_accuracy: 0.3064\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 12577.6045 - accuracy: 0.3085 - val_loss: 8492.7793 - val_accuracy: 0.2189\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 8405.8369 - accuracy: 0.2187 - val_loss: 9412.0713 - val_accuracy: 0.3391\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 9382.2939 - accuracy: 0.3432 - val_loss: 11261.1982 - val_accuracy: 0.2000\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 11184.6895 - accuracy: 0.1995 - val_loss: 10682.4844 - val_accuracy: 0.3430\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 10598.0625 - accuracy: 0.3477 - val_loss: 7578.3530 - val_accuracy: 0.5087\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 7503.8530 - accuracy: 0.5127 - val_loss: 7097.8447 - val_accuracy: 0.4717\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 7020.2290 - accuracy: 0.4712 - val_loss: 4707.9951 - val_accuracy: 0.5441\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 4627.3804 - accuracy: 0.5517 - val_loss: 4099.3086 - val_accuracy: 0.4801\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 4039.9207 - accuracy: 0.4833 - val_loss: 4210.3262 - val_accuracy: 0.4802\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 4150.1235 - accuracy: 0.4867 - val_loss: 3975.3652 - val_accuracy: 0.5109\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 3901.2839 - accuracy: 0.5177 - val_loss: 2933.0559 - val_accuracy: 0.5274\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2849.4443 - accuracy: 0.5364 - val_loss: 3921.3428 - val_accuracy: 0.5587\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 3841.2837 - accuracy: 0.5724 - val_loss: 2828.8315 - val_accuracy: 0.6024\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2774.9675 - accuracy: 0.6088 - val_loss: 2453.8535 - val_accuracy: 0.5706\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2421.4954 - accuracy: 0.5752 - val_loss: 2882.0168 - val_accuracy: 0.6297\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 2810.0903 - accuracy: 0.6376 - val_loss: 2386.7808 - val_accuracy: 0.6072\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2327.8687 - accuracy: 0.6154 - val_loss: 2998.9685 - val_accuracy: 0.6623\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2946.3601 - accuracy: 0.6721 - val_loss: 4569.8120 - val_accuracy: 0.5865\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 1s 12us/sample - loss: 4463.7471 - accuracy: 0.5936 - val_loss: 2346.7576 - val_accuracy: 0.6380\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 1s 9us/sample - loss: 2310.2646 - accuracy: 0.6405 - val_loss: 2015.9900 - val_accuracy: 0.5547\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 1s 10us/sample - loss: 1945.2147 - accuracy: 0.5598 - val_loss: 3858.2424 - val_accuracy: 0.6500\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 1s 9us/sample - loss: 3808.5935 - accuracy: 0.6603 - val_loss: 4136.3472 - val_accuracy: 0.6334\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 1s 10us/sample - loss: 4067.7466 - accuracy: 0.6367 - val_loss: 2825.2268 - val_accuracy: 0.6700\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 1s 10us/sample - loss: 2786.7307 - accuracy: 0.6714 - val_loss: 1817.7249 - val_accuracy: 0.7037\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 1s 9us/sample - loss: 1764.7261 - accuracy: 0.7143 - val_loss: 963.0390 - val_accuracy: 0.7088\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 1s 11us/sample - loss: 925.1883 - accuracy: 0.7168 - val_loss: 1851.0492 - val_accuracy: 0.6167\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 1758.9735 - accuracy: 0.6302 - val_loss: 3166.0037 - val_accuracy: 0.7113\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 3123.2229 - accuracy: 0.7223 - val_loss: 1924.8696 - val_accuracy: 0.7079\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1891.8324 - accuracy: 0.7178 - val_loss: 1283.6342 - val_accuracy: 0.6682\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 1241.3048 - accuracy: 0.6707 - val_loss: 2660.4172 - val_accuracy: 0.6102\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2561.5039 - accuracy: 0.6176 - val_loss: 1872.9596 - val_accuracy: 0.6383\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1821.7101 - accuracy: 0.6472 - val_loss: 1738.3276 - val_accuracy: 0.6353\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 1675.2703 - accuracy: 0.6395 - val_loss: 2377.6079 - val_accuracy: 0.5630\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2297.3796 - accuracy: 0.5719 - val_loss: 2136.9392 - val_accuracy: 0.6596\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 2074.0464 - accuracy: 0.6625 - val_loss: 2038.7823 - val_accuracy: 0.6997\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1982.6504 - accuracy: 0.7100 - val_loss: 849.3596 - val_accuracy: 0.7349\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 811.6995 - accuracy: 0.7423 - val_loss: 1566.3188 - val_accuracy: 0.6357\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1471.1757 - accuracy: 0.6479 - val_loss: 3289.7043 - val_accuracy: 0.6982\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 3234.9172 - accuracy: 0.7082 - val_loss: 1959.3580 - val_accuracy: 0.7060\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 1919.3381 - accuracy: 0.7115 - val_loss: 2558.5007 - val_accuracy: 0.6652\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 2513.3250 - accuracy: 0.6697 - val_loss: 2570.2908 - val_accuracy: 0.6880\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2479.9792 - accuracy: 0.7036 - val_loss: 2842.0215 - val_accuracy: 0.6895\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2785.5342 - accuracy: 0.6963 - val_loss: 2760.6121 - val_accuracy: 0.6793\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2719.8479 - accuracy: 0.6850 - val_loss: 2529.2725 - val_accuracy: 0.6594\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2436.3430 - accuracy: 0.6740 - val_loss: 3239.1387 - val_accuracy: 0.6770\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f12698a0fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JdzDtGwDOIVF"
      },
      "source": [
        "### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kndfpdidOIVI",
        "colab": {}
      },
      "source": [
        "# Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Reshape data from 2D to 1D -> 28x28 to 784\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "\n",
        "# Normalize the data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "# Add Dense Layer which provides 10 Outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Comile the model\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mwk3T5LJOIVN"
      },
      "source": [
        "### Execute the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JNLR8tcBOIVP",
        "outputId": "9194b9b5-9f31-4b5c-a2a3-f387cf7c7a06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(trainX, trainY, validation_data=(testX, testY), epochs=50, batch_size = trainX.shape[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 3.2483 - accuracy: 0.0811 - val_loss: 30.4160 - val_accuracy: 0.1037\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 1s 17us/sample - loss: 2.9163 - accuracy: 0.1081 - val_loss: 16.3628 - val_accuracy: 0.1220\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 2.6447 - accuracy: 0.1383 - val_loss: 10.4811 - val_accuracy: 0.1515\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 2.4196 - accuracy: 0.1724 - val_loss: 7.5213 - val_accuracy: 0.1909\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 2.2317 - accuracy: 0.2101 - val_loss: 5.9218 - val_accuracy: 0.2319\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 2.0744 - accuracy: 0.2491 - val_loss: 4.9738 - val_accuracy: 0.2648\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.9424 - accuracy: 0.2898 - val_loss: 4.3510 - val_accuracy: 0.2950\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.8315 - accuracy: 0.3306 - val_loss: 3.9110 - val_accuracy: 0.3193\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.7378 - accuracy: 0.3686 - val_loss: 3.5835 - val_accuracy: 0.3399\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.6583 - accuracy: 0.4017 - val_loss: 3.3289 - val_accuracy: 0.3554\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.5901 - accuracy: 0.4306 - val_loss: 3.1238 - val_accuracy: 0.3741\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.5312 - accuracy: 0.4550 - val_loss: 2.9534 - val_accuracy: 0.3899\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.4798 - accuracy: 0.4765 - val_loss: 2.8081 - val_accuracy: 0.4034\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.4346 - accuracy: 0.4945 - val_loss: 2.6813 - val_accuracy: 0.4185\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.3945 - accuracy: 0.5100 - val_loss: 2.5688 - val_accuracy: 0.4335\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.3585 - accuracy: 0.5232 - val_loss: 2.4676 - val_accuracy: 0.4449\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.3261 - accuracy: 0.5352 - val_loss: 2.3758 - val_accuracy: 0.4559\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2967 - accuracy: 0.5468 - val_loss: 2.2917 - val_accuracy: 0.4668\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 1.2699 - accuracy: 0.5568 - val_loss: 2.2142 - val_accuracy: 0.4748\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2452 - accuracy: 0.5663 - val_loss: 2.1425 - val_accuracy: 0.4832\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2224 - accuracy: 0.5748 - val_loss: 2.0759 - val_accuracy: 0.4923\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.2014 - accuracy: 0.5833 - val_loss: 2.0139 - val_accuracy: 0.4995\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.1818 - accuracy: 0.5906 - val_loss: 1.9559 - val_accuracy: 0.5084\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.1635 - accuracy: 0.5979 - val_loss: 1.9017 - val_accuracy: 0.5180\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.1463 - accuracy: 0.6045 - val_loss: 1.8509 - val_accuracy: 0.5265\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.1302 - accuracy: 0.6108 - val_loss: 1.8032 - val_accuracy: 0.5338\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.1151 - accuracy: 0.6174 - val_loss: 1.7584 - val_accuracy: 0.5398\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.1008 - accuracy: 0.6232 - val_loss: 1.7162 - val_accuracy: 0.5469\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.0873 - accuracy: 0.6282 - val_loss: 1.6764 - val_accuracy: 0.5544\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.0746 - accuracy: 0.6335 - val_loss: 1.6388 - val_accuracy: 0.5619\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0624 - accuracy: 0.6382 - val_loss: 1.6033 - val_accuracy: 0.5666\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0509 - accuracy: 0.6435 - val_loss: 1.5698 - val_accuracy: 0.5722\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0399 - accuracy: 0.6477 - val_loss: 1.5380 - val_accuracy: 0.5792\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.0295 - accuracy: 0.6516 - val_loss: 1.5078 - val_accuracy: 0.5839\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0195 - accuracy: 0.6557 - val_loss: 1.4792 - val_accuracy: 0.5885\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0099 - accuracy: 0.6598 - val_loss: 1.4520 - val_accuracy: 0.5924\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0008 - accuracy: 0.6626 - val_loss: 1.4262 - val_accuracy: 0.5975\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9920 - accuracy: 0.6663 - val_loss: 1.4015 - val_accuracy: 0.6018\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9836 - accuracy: 0.6694 - val_loss: 1.3780 - val_accuracy: 0.6062\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9756 - accuracy: 0.6728 - val_loss: 1.3556 - val_accuracy: 0.6109\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9678 - accuracy: 0.6756 - val_loss: 1.3343 - val_accuracy: 0.6141\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.9604 - accuracy: 0.6786 - val_loss: 1.3138 - val_accuracy: 0.6172\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9532 - accuracy: 0.6812 - val_loss: 1.2942 - val_accuracy: 0.6199\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9462 - accuracy: 0.6835 - val_loss: 1.2755 - val_accuracy: 0.6239\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9396 - accuracy: 0.6861 - val_loss: 1.2576 - val_accuracy: 0.6286\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.9331 - accuracy: 0.6882 - val_loss: 1.2403 - val_accuracy: 0.6321\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9269 - accuracy: 0.6907 - val_loss: 1.2238 - val_accuracy: 0.6351\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9208 - accuracy: 0.6926 - val_loss: 1.2079 - val_accuracy: 0.6380\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9150 - accuracy: 0.6942 - val_loss: 1.1927 - val_accuracy: 0.6408\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.9094 - accuracy: 0.6963 - val_loss: 1.1780 - val_accuracy: 0.6444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1268322048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Py-KwkmjOIVU"
      },
      "source": [
        "### Customize the learning rate to 0.001 in sgd optimizer and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yLXUE9jWOIVV",
        "colab": {}
      },
      "source": [
        "# Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Reshape data from 2D to 1D -> 28x28 to 784\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "\n",
        "# Normalize the data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "# Add Dense Layer which provides 10 Outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "sgd = tf.keras.optimizers.SGD(lr=0.001)\n",
        "\n",
        "# Comile the model\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pJUqA5T4OIVc",
        "outputId": "85e45b67-1ead-4855-e925-71936f7c4413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(trainX, trainY, validation_data=(testX, testY), epochs=50, batch_size = trainX.shape[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 3.0347 - accuracy: 0.0658 - val_loss: 19.2231 - val_accuracy: 0.1200\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 2.7339 - accuracy: 0.1050 - val_loss: 12.0361 - val_accuracy: 0.1664\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 2.4896 - accuracy: 0.1584 - val_loss: 9.0229 - val_accuracy: 0.1905\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 2.2900 - accuracy: 0.2185 - val_loss: 7.2766 - val_accuracy: 0.2126\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 2.1259 - accuracy: 0.2727 - val_loss: 6.1038 - val_accuracy: 0.2358\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.9901 - accuracy: 0.3152 - val_loss: 5.2585 - val_accuracy: 0.2594\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.8770 - accuracy: 0.3510 - val_loss: 4.6269 - val_accuracy: 0.2856\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.7821 - accuracy: 0.3818 - val_loss: 4.1433 - val_accuracy: 0.3126\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.7018 - accuracy: 0.4095 - val_loss: 3.7645 - val_accuracy: 0.3386\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.6332 - accuracy: 0.4330 - val_loss: 3.4610 - val_accuracy: 0.3611\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.5740 - accuracy: 0.4530 - val_loss: 3.2124 - val_accuracy: 0.3798\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.5224 - accuracy: 0.4707 - val_loss: 3.0050 - val_accuracy: 0.3996\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.4768 - accuracy: 0.4866 - val_loss: 2.8293 - val_accuracy: 0.4186\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.4363 - accuracy: 0.5011 - val_loss: 2.6783 - val_accuracy: 0.4342\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.3999 - accuracy: 0.5139 - val_loss: 2.5469 - val_accuracy: 0.4491\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 1.3670 - accuracy: 0.5249 - val_loss: 2.4314 - val_accuracy: 0.4635\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.3370 - accuracy: 0.5353 - val_loss: 2.3289 - val_accuracy: 0.4746\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.3096 - accuracy: 0.5453 - val_loss: 2.2374 - val_accuracy: 0.4872\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.2843 - accuracy: 0.5538 - val_loss: 2.1550 - val_accuracy: 0.4987\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.2610 - accuracy: 0.5624 - val_loss: 2.0805 - val_accuracy: 0.5076\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.2393 - accuracy: 0.5709 - val_loss: 2.0127 - val_accuracy: 0.5172\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.2192 - accuracy: 0.5778 - val_loss: 1.9508 - val_accuracy: 0.5272\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.2004 - accuracy: 0.5845 - val_loss: 1.8940 - val_accuracy: 0.5347\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.1827 - accuracy: 0.5910 - val_loss: 1.8418 - val_accuracy: 0.5436\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.1662 - accuracy: 0.5967 - val_loss: 1.7934 - val_accuracy: 0.5517\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.1506 - accuracy: 0.6023 - val_loss: 1.7486 - val_accuracy: 0.5609\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.1359 - accuracy: 0.6076 - val_loss: 1.7069 - val_accuracy: 0.5678\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.1220 - accuracy: 0.6121 - val_loss: 1.6681 - val_accuracy: 0.5742\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.1088 - accuracy: 0.6164 - val_loss: 1.6317 - val_accuracy: 0.5796\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0963 - accuracy: 0.6211 - val_loss: 1.5976 - val_accuracy: 0.5849\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0844 - accuracy: 0.6254 - val_loss: 1.5655 - val_accuracy: 0.5903\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.0731 - accuracy: 0.6293 - val_loss: 1.5353 - val_accuracy: 0.5950\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0623 - accuracy: 0.6332 - val_loss: 1.5068 - val_accuracy: 0.5997\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0520 - accuracy: 0.6369 - val_loss: 1.4799 - val_accuracy: 0.6032\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0422 - accuracy: 0.6405 - val_loss: 1.4543 - val_accuracy: 0.6071\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0327 - accuracy: 0.6439 - val_loss: 1.4301 - val_accuracy: 0.6100\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0237 - accuracy: 0.6469 - val_loss: 1.4071 - val_accuracy: 0.6142\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0151 - accuracy: 0.6502 - val_loss: 1.3851 - val_accuracy: 0.6182\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0067 - accuracy: 0.6529 - val_loss: 1.3642 - val_accuracy: 0.6212\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9987 - accuracy: 0.6558 - val_loss: 1.3443 - val_accuracy: 0.6240\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9910 - accuracy: 0.6587 - val_loss: 1.3252 - val_accuracy: 0.6263\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9836 - accuracy: 0.6612 - val_loss: 1.3070 - val_accuracy: 0.6294\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9765 - accuracy: 0.6632 - val_loss: 1.2895 - val_accuracy: 0.6326\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.9695 - accuracy: 0.6653 - val_loss: 1.2727 - val_accuracy: 0.6344\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9629 - accuracy: 0.6680 - val_loss: 1.2567 - val_accuracy: 0.6375\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9564 - accuracy: 0.6701 - val_loss: 1.2412 - val_accuracy: 0.6397\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9502 - accuracy: 0.6716 - val_loss: 1.2264 - val_accuracy: 0.6432\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9442 - accuracy: 0.6738 - val_loss: 1.2121 - val_accuracy: 0.6454\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9383 - accuracy: 0.6758 - val_loss: 1.1983 - val_accuracy: 0.6477\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9327 - accuracy: 0.6779 - val_loss: 1.1850 - val_accuracy: 0.6497\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1267680748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j9CSqKvpOIVk"
      },
      "source": [
        "### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GGAad54JOIVm",
        "colab": {}
      },
      "source": [
        "# Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Reshape data from 2D to 1D -> 28x28 to 784\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "\n",
        "# Normalize the data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "# Hidden layers\n",
        "model.add(tf.keras.layers.Dense(100, activation='sigmoid', name='Layer_1'))\n",
        "model.add(tf.keras.layers.Dense(100, activation='sigmoid', name='Layer_2'))\n",
        "model.add(tf.keras.layers.Dense(100, activation='sigmoid', name='Layer_3'))\n",
        "\n",
        "#Output layer\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax', name='Output'))\n",
        "\n",
        "sgd = tf.keras.optimizers.SGD(lr=0.03)\n",
        "\n",
        "# Comile the model\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Nr2YsZV0OIV0"
      },
      "source": [
        "## Review model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h4ojW6-oOIV2",
        "outputId": "45fdc635-749f-4c15-b140-ab75f5f814d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_3 (Reshape)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 784)               3136      \n",
            "_________________________________________________________________\n",
            "Layer_1 (Dense)              (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "Layer_2 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "Layer_3 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "Output (Dense)               (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 102,846\n",
            "Trainable params: 101,278\n",
            "Non-trainable params: 1,568\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gfFGmbZLOIV5"
      },
      "source": [
        "### Run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bIkbMEN5OIV7",
        "outputId": "3a023c84-b63b-4986-f7dc-4808394f8ad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(trainX, trainY, validation_data=(testX, testY), epochs=30, batch_size = 32)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 2.2258 - accuracy: 0.2729 - val_loss: 2.0583 - val_accuracy: 0.4269\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 1.7415 - accuracy: 0.4845 - val_loss: 1.4570 - val_accuracy: 0.5495\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 1.2782 - accuracy: 0.6097 - val_loss: 1.1065 - val_accuracy: 0.6735\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 1.0069 - accuracy: 0.6898 - val_loss: 0.8804 - val_accuracy: 0.7223\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 7s 119us/sample - loss: 0.8238 - accuracy: 0.7266 - val_loss: 0.7427 - val_accuracy: 0.7459\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 7s 125us/sample - loss: 0.7180 - accuracy: 0.7458 - val_loss: 0.6671 - val_accuracy: 0.7571\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.6579 - accuracy: 0.7615 - val_loss: 0.6211 - val_accuracy: 0.7681\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.6166 - accuracy: 0.7760 - val_loss: 0.5847 - val_accuracy: 0.7900\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.5835 - accuracy: 0.7909 - val_loss: 0.5590 - val_accuracy: 0.8002\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.5585 - accuracy: 0.8010 - val_loss: 0.5390 - val_accuracy: 0.8041\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.5387 - accuracy: 0.8097 - val_loss: 0.5235 - val_accuracy: 0.8104\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.5212 - accuracy: 0.8153 - val_loss: 0.5087 - val_accuracy: 0.8181\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.5044 - accuracy: 0.8209 - val_loss: 0.4974 - val_accuracy: 0.8232\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 7s 110us/sample - loss: 0.4924 - accuracy: 0.8272 - val_loss: 0.4852 - val_accuracy: 0.8265\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 7s 111us/sample - loss: 0.4791 - accuracy: 0.8316 - val_loss: 0.4768 - val_accuracy: 0.8306\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4737 - accuracy: 0.8330 - val_loss: 0.4699 - val_accuracy: 0.8342\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.4611 - accuracy: 0.8370 - val_loss: 0.4642 - val_accuracy: 0.8350\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.4541 - accuracy: 0.8411 - val_loss: 0.4558 - val_accuracy: 0.8381\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 7s 119us/sample - loss: 0.4466 - accuracy: 0.8417 - val_loss: 0.4496 - val_accuracy: 0.8425\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.4362 - accuracy: 0.8463 - val_loss: 0.4440 - val_accuracy: 0.8437\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 7s 119us/sample - loss: 0.4327 - accuracy: 0.8465 - val_loss: 0.4366 - val_accuracy: 0.8462\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.4258 - accuracy: 0.8497 - val_loss: 0.4301 - val_accuracy: 0.8484\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.4169 - accuracy: 0.8515 - val_loss: 0.4260 - val_accuracy: 0.8480\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 7s 111us/sample - loss: 0.4116 - accuracy: 0.8547 - val_loss: 0.4240 - val_accuracy: 0.8514\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4083 - accuracy: 0.8560 - val_loss: 0.4183 - val_accuracy: 0.8517\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 7s 112us/sample - loss: 0.4012 - accuracy: 0.8583 - val_loss: 0.4147 - val_accuracy: 0.8552\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 6s 108us/sample - loss: 0.3952 - accuracy: 0.8596 - val_loss: 0.4092 - val_accuracy: 0.8557\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.3909 - accuracy: 0.8603 - val_loss: 0.4042 - val_accuracy: 0.8586\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3847 - accuracy: 0.8639 - val_loss: 0.4038 - val_accuracy: 0.8567\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.3801 - accuracy: 0.8646 - val_loss: 0.3981 - val_accuracy: 0.8595\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f12af327860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "R7_Internal_Lab_Questions_FMNIST_Simple_CNN_updated.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MyfMmMnPJjvn"
      },
      "source": [
        "## Train a simple convnet on the Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zjcGOJhcJjvp"
      },
      "source": [
        "In this, we will see how to deal with image data and train a convnet for image classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvbL1jmax1dx",
        "colab_type": "text"
      },
      "source": [
        "###1. Import and set and Tensorflow 2 and verify version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqhs2LTNx0lQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "tf.__version__\n",
        "tf.set_random_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jR0Pl2XjJjvq"
      },
      "source": [
        "### 2. Load the  `fashion_mnist`  dataset\n",
        "\n",
        "** Use keras.datasets to load the dataset **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qr75v_UYJjvs",
        "colab": {}
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59ST88LoMyxr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "e9e6fe99-26f0-4758-9e03-51ad0756d13e"
      },
      "source": [
        "print(\"Shape of x_train : \", x_train.shape)\n",
        "print(\"Shape of x_test : \", x_test.shape)\n",
        "print(\"Shape of y_train : \", y_train.shape)\n",
        "print(\"Shape of y_test : \", y_test.shape)"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_train :  (60000, 28, 28)\n",
            "Shape of x_test :  (10000, 28, 28)\n",
            "Shape of y_train :  (60000,)\n",
            "Shape of y_test :  (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf2NG5NJ05w_",
        "colab_type": "text"
      },
      "source": [
        "###3. Create a list 'class_names' of below Class Names\n",
        "**Class - Class Name** ==> \n",
        "0 - T-shirt, \n",
        "1 - Trouser, \n",
        "2 - Pullover, \n",
        "3 - Dress, \n",
        "4 - Coat, \n",
        "5 - Sandal, \n",
        "6 - Shirt, \n",
        "7 - Sneaker, \n",
        "8 - Bag, \n",
        "9 - Ankle boot,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30E9G9cRRxwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mapping Classes : \n",
        "class_names = {0 : 'T-shirt', 1 : 'Trouser', 2 : 'Pullover', 3 : 'Dress', 4 : 'Coat', 5 : 'Sandal', 6 : 'Shirt', 7 : 'Sneaker', 8 : 'Bag', 9 : 'Ankle boot'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hTI42-0qJjvw"
      },
      "source": [
        "###4. Find no.of samples in training and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g2sf67VoJjvx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9f9c6468-fe13-45a1-9f20-6f093d749c70"
      },
      "source": [
        "#Check number of training examples and size of each example.\n",
        "print(\"Shape of x_train : \", x_train.shape)\n",
        "\n",
        "print(\"Fashion MNIST train -  No. Of Samples :\",x_train.shape[0])"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_train :  (60000, 28, 28)\n",
            "Fashion MNIST train -  No. Of Samples : 60000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zewyDcBlJjv1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c920d1f8-6129-454b-fcc9-df42e44b9df1"
      },
      "source": [
        "#Check number of test examples and size of each example.\n",
        "print(\"Shape of x_test : \", x_test.shape)\n",
        "\n",
        "print(\"Fashion MNIST test -  No. Of Samples :\",x_test.shape[0])"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_test :  (10000, 28, 28)\n",
            "Fashion MNIST test -  No. Of Samples : 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WytT2eRnJjv4"
      },
      "source": [
        "###5. Find dimensions of an image in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XycQGBSGJjv5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "ad8ea0fb-9aa1-46a8-a969-062c3979ea14"
      },
      "source": [
        "print(\"Shape of x_train : \", x_train.shape)\n",
        "print(\"Shape of x_test : \", x_test.shape)\n",
        "print(\"Fashion MNIST train -  No. Of Dimensions :\", x_train.shape[1])\n",
        "print(\"Fashion MNIST test -  No. Of Dimensions :\", x_test.shape[1])"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_train :  (60000, 28, 28)\n",
            "Shape of x_test :  (10000, 28, 28)\n",
            "Fashion MNIST train -  No. Of Dimensions : 28\n",
            "Fashion MNIST test -  No. Of Dimensions : 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJaUaIKATSVr",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### 6. Verify if existing labels/Classes are correct "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAzXREYjTRhn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "9cf2f167-6f49-479c-c3e4-0670d172be1f"
      },
      "source": [
        "#Lets print the image as well.\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "#fig, axes = plt.subplots(4, 4, figsize = (15,15))\n",
        "img_num = np.random.randint(0,x_test.shape[0])\n",
        "plt.imshow(x_test[img_num],cmap='gray')\n",
        "plt.suptitle(str(y_test[img_num]))\n",
        "plt.show()"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEVCAYAAAAmS5PgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8I4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5jtdZ7RqJjv8"
      },
      "source": [
        "\n",
        "### 7. Convert train and test labels to one hot vectors\n",
        "\n",
        "** check `tensorflow.keras.utils.to_categorical()` **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sAD3q5I6Jjv9",
        "colab": {}
      },
      "source": [
        "#Convert labels to one hot encoding\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9o4q7NJNUpi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "908c1b18-f9e3-4bfd-e63f-ee4b6dbdbcef"
      },
      "source": [
        "print(\"Shape of x_train : \", x_train.shape)\n",
        "print(\"Shape of x_test  : \", x_test.shape)\n",
        "print(\"Shape of y_train : \", y_train.shape)\n",
        "print(\"Shape of y_test  : \", y_test.shape)"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_train :  (60000, 28, 28)\n",
            "Shape of x_test  :  (10000, 28, 28)\n",
            "Shape of y_train :  (60000, 10)\n",
            "Shape of y_test  :  (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xO5BRBzBJjwD"
      },
      "source": [
        "###8. Normalize both the train and test image data from 0-255 to 0-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3fUQpMHxJjwE",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype(\"float32\")/255\n",
        "x_test = x_test.astype(\"float32\")/255\n",
        "y_train = y_train.astype(\"float32\")/255\n",
        "y_test = y_test.astype(\"float32\")/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "da5-DwgrJjwM"
      },
      "source": [
        "###9. Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras\n",
        "check `tensorflow.keras.backend.expand_dims`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LPGVQ-JJJjwN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "a46eb9d1-3d15-4a0c-a4dd-d61d596bab95"
      },
      "source": [
        "print(\"Shape of x_train : \", x_train.shape)\n",
        "print(\"Shape of x_test  : \", x_test.shape)\n",
        "print(\"Shape of y_train : \", y_train.shape)\n",
        "print(\"Shape of y_test  : \", y_test.shape)"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_train :  (60000, 28, 28)\n",
            "Shape of x_test  :  (10000, 28, 28)\n",
            "Shape of y_train :  (60000, 10)\n",
            "Shape of y_test  :  (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3tQrezrMFgV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a1c29d7a-8937-472d-ff3d-934e8aaf6ceb"
      },
      "source": [
        "tf.keras.backend.expand_dims(x_train,axis=-1)\n",
        "tf.keras.backend.expand_dims(x_test,axis=-1)"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'ExpandDims_1:0' shape=(10000, 28, 28, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OFRRTJq8JjwQ"
      },
      "source": [
        "###10. Import the necessary layers from keras to build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dWTZYnKSJjwR",
        "colab": {}
      },
      "source": [
        "#Clear out tensorflow memory\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#Normalize the data\n",
        "model.add(tf.keras.layers.BatchNormalization())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C18AoS7eJjwU"
      },
      "source": [
        "### 11. Build a model \n",
        "\n",
        "** with 2 Conv layers having `32 3x3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with no.of `epochs=10`. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DORCLgSwJjwV",
        "colab": {}
      },
      "source": [
        "#Add first convolutional layer\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, #Number of filters \n",
        "                                 kernel_size=(3,3), #Size of the filter\n",
        "                                 activation='relu'))\n",
        "\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add second convolutional layer\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "#Add MaxPooling layer\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#Flatten the output\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "#Dense layer\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ju69vKdIJjwX"
      },
      "source": [
        "###12. Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbPBRoIRRiJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add another dropout layer\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "#Output layer\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "#Compile the model.  \n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MwQQW5iOJjwq"
      },
      "source": [
        "###13. Verify accuracy of the model\n",
        "\n",
        "> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L2hAP94vJjwY",
        "colab": {}
      },
      "source": [
        "mckpt = tf.keras.callbacks.ModelCheckpoint('./mnist_v1.h5', \n",
        "                                           monitor='val_acc', save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS7jrRFaQWe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(x_train,y_train,          \n",
        "          validation_data=(x_test,y_test),\n",
        "          epochs=5,\n",
        "          batch_size=32, callbacks=[mckpt])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_m60wsrX6hh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.get_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfjNBWhbZ2KM",
        "colab_type": "text"
      },
      "source": [
        "####14. Verify performance of your model selectively "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erPkStxJaHEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(x_train)\n",
        "\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array, true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks(range(9), class_names, rotation=90)\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color='blue')\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFPzCbnDaYAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Replace value of i with other index to check other product\n",
        "i = 5\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions[i], y_train, x_train)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions[i],  y_train)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lGTA3bfEJjwa"
      },
      "source": [
        "### Now, to the above model, lets add Data Augmentation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F6gX8n5SJjwb"
      },
      "source": [
        "###15. Import the ImageDataGenrator from keras and fit the training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cbz4uHBuJjwc",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        rotation_range = 8,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        shear_range = 0.3,# shear angle in counter-clockwise direction in degrees  \n",
        "        width_shift_range=0.08,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.08,  # randomly shift images vertically (fraction of total height)\n",
        "        vertical_flip=True)  # randomly flip images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8spTjWYRRZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pl-8dOo7Jjwf"
      },
      "source": [
        "####16. Showing 5 versions of the first image in training dataset using image datagenerator.flow()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DpI1_McYJjwg",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = datagen.flow(x_train[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c1SrtBEPJjwq",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZBwVWNQC2qZD",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}